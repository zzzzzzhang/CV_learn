# -*- coding: utf-8 -*-
"""Network_MainBody.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hJdQwnZU2uCs51WZt8VpCjZf8qigoUHY
"""

# # 授权访问谷歌云盘
# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools
# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
# !apt-get update -qq 2>&1 > /dev/null
# !apt-get -y install -qq google-drive-ocamlfuse fuse
# from google.colab import auth
# auth.authenticate_user()
# from oauth2client.client import GoogleCredentials
# creds = GoogleCredentials.get_application_default()
# import getpass
# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
# vcode = getpass.getpass()
# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

# #建立根目录
# !mkdir -p drive
# !google-drive-ocamlfuse drive

import os
import pandas as pd
import matplotlib.pyplot as plt
from torch.utils.data import  DataLoader
import torch
from torchvision.transforms import transforms
from PIL import Image
import random
from torch import optim
import torch.nn as nn
from torch.optim import lr_scheduler
import copy

os.chdir('/content/drive/Colab Notebooks/project1_classification/Stage_2 Species_classification')
from Network_Species import *
!ls

root_dir = '/content/drive/Colab Notebooks/project1_classification/'
train_dir = 'train/'
val_dir = 'val/'
train_anno = 'Species_train_annotation.csv'
val_anno = 'Species_val_annotation.csv'
species = ['rabbits', 'rats', 'chickens']

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3,3,3)
        self.maxpool1 = nn.MaxPool2d(kernel_size= 2)
        self.relu1 = nn.ReLU(inplace= True)
        
        self.conv2 = nn.Conv2d(3,6,3)
        self.maxpool2 = nn.MaxPool2d(kernel_size= 2)
        self.relu2 = nn.ReLU(inplace= True)
        
        self.fc1 = nn.Linear(6 * 30 * 30, 150)
        self.relu3 = nn.ReLU(inplace= True)
        
        self.drop = nn.Dropout(p = 0.5)
        self.fc2 = nn.Linear(150,3)
        self.softmax = nn.Softmax(dim = 1)
    
    def forward(self, x):
        x = self.conv1(x)
        x = self.maxpool1(x)
        x = self.relu1(x)
        
        x = self.conv2(x)
        x = self.maxpool2(x)
        x = self.relu2(x)
        
        x = x.view(-1, 6 * 30 * 30)
        
        x = self.fc1(x)
        x = self.relu3(x)
        x = self.drop(x)
        
        x = self.fc2(x)
        x_class = self.softmax(x)
        
        return x_class

class myDataset():
    '''
    用于获取图片数据
    '''
    def __init__(self, root_dir, annotations_file, transform= None):
        self.rootdir = root_dir
        self.annotations_file = annotations_file
        self.transform = transform
        
        if not os.path.isfile(self.annotations_file):
            print(self.annotations_file + 'does not exis!')
        
        self.file_info = pd.read_csv(annotations_file, index_col= None)
        self.size = len(self.file_info)
    
    def __call__(self):
        print('使用__getitem__(idx)获取图片数据')
    
    def __len__(self):
        return self.size
    
    def __getitem__(self, idx):
        '''
        定义了__getitem__魔法函数，该类就可以下标操作了：[]
        '''
        image_path = self.file_info['path'][idx]
        if not os.path.isfile(image_path):
            print(image_path + 'does not exis!')
            return None
        
        image = Image.open(image_path).convert('RGB')
        label_class = int(self.file_info['species'][idx])
        sample = {'image': image, 'species': label_class}
        
        if self.transform:
            sample['image'] = self.transform(image)
        
        return sample

#transforms:按顺序进行相应transform操作
pitcureSize = 128

train_tranfroms = transforms.Compose([transforms.Resize([pitcureSize, pitcureSize]),
                                      transforms.RandomHorizontalFlip(p = 0.5),
                                      transforms.ToTensor()
                                     ])
val_tranfroms = transforms.Compose([transforms.Resize([pitcureSize, pitcureSize]),
                                      transforms.ToTensor()
                                   ])
# 将数据路径实例化
train_dataset = myDataset(root_dir= root_dir + train_dir, 
                          annotations_file= train_anno, 
                          transform = train_tranfroms
                         )
val_dataset = myDataset(root_dir= root_dir + val_dir, 
                        annotations_file= val_anno, 
                        transform = val_tranfroms
                       )

# 转化为Dataloader
train_loader = DataLoader(dataset= train_dataset, batch_size= 512, shuffle= True)
val_loader = DataLoader(dataset= val_dataset)
data_loaders = {'train': train_loader, 'val': val_loader}

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)

def visualize_dataset(idx):
    '''
    数据可视化
    '''
    print(len(train_dataset))
    #提取第idx个数据
    sample = train_loader.dataset[idx]
    #sample['image'] ：tensor of image 
    print(idx, sample['image'].shape, species[sample['species']])
    img = sample['image']
    plt.imshow(transforms.ToPILImage()(img))
    plt.show()
visualize_dataset(520)

def train_model(model, data_loaders, criterion, optimizer, scheduler, num_epochs= 50):
    '''
    model: 需要训练的网络
    criterion：评价标准
    optimizer：优化器
    scheduler：学习率衰减
    num_epochs：迭代次数
    '''
    loss_list = {'train':[], 'val':[]}
    accuracy_list_species = {'train':[], 'val':[]}
    #保存最好的模型与精度
    best_model_weights = copy.deepcopy(model.state_dict())
    best_acc = 0.0
    
    for epoch in range(num_epochs):
        print('Epoch{}/{}'.format(epoch + 1, num_epochs))
        print('-*' * 10)
        #每个epoch都需要进行一次训练与验证的过程
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()
            running_loss = 0.0
            corrects_species = 0
            for idx, data in enumerate(data_loaders[phase]):
                if phase == 'train':
                    print('training batch:{}'.format(idx))
                inputs = data['image'].to(device)
                labels_species = data['species'].to(device)
                #每个batch都需要重新计算梯度，所以清空
                optimizer.zero_grad()
                
                #只有在训练过程中需要反向传播，所以测试过程中可以set_grad_enabled(Flase)
                with torch.set_grad_enabled(phase == 'train'):
                    x_species = model(inputs)
                    #得到的是species概率，需要继续转为类别
                    x_species = x_species.view(-1, 3)
                    #preds_species对应第几列的索引，即0还是1,2
                    _, preds_species = torch.max(x_species, 1)
                    #这里的 nn.CrossEntropyLoss()中第二个参数可以理解是groundtruth中‘1’的位置
                    loss = criterion(x_species, labels_species)
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                #loss.item() 返回一个value，乘以一个input.size，防止最后一组input数量不等
                running_loss += loss.item() * inputs.size(0)
                #计算正确分类的个数
                corrects_species += torch.sum(preds_species == labels_species)
            #求batch的loss
            epoch_loss = running_loss/len(data_loaders[phase].dataset)
            loss_list[phase].append(epoch_loss)
            
            epoch_acc_species = corrects_species.double() / len(data_loaders[phase].dataset)
            epoch_acc = epoch_acc_species
            #乘以100应该是为了后面显示（）% ???
            accuracy_list_species[phase].append(100 * epoch_acc_species)
            #用测试集测试，记录最佳权值
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc_species
                best_model_weights = copy.deepcopy(model.state_dict())
                print('Best val species Acc: {:.2%}'.format(best_acc))
        
            print('{} Loss: {:.4f}  Acc_species: {:.2%}'.format(phase, epoch_loss,epoch_acc_species))
        #学习率衰减
        # scheduler.step()
            
    model.load_state_dict(best_model_weights)
    torch.save(model.state_dict(),'Acc_{:04d}.pt'.format(round(best_acc.item() * 100)))
    print('Best val species Acc: {:.2%}'.format(best_acc))
    return model, loss_list, accuracy_list_species

network = Net().to(device)
# network.load_state_dict(torch.load('Acc_0072'))
optimizer = optim.Adam(network.parameters(), lr=0.01)
criterion = nn.CrossEntropyLoss()
#每步衰减至0.9 * 上步学习率
exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size= 5, gamma= 0.5)
#训练网络
num_epochs = 10
model, loss_list, accuracy_list_species = train_model(network, 
                            data_loaders, 
                            criterion, 
                            optimizer, 
                            exp_lr_scheduler, 
                            num_epochs= num_epochs)

x = range(0, num_epochs)
y1 = loss_list["val"]
y2 = loss_list["train"]

plt.plot(x, y1, color="r", linestyle="-", marker="o", linewidth=1, label="val")
plt.plot(x, y2, color="b", linestyle="-", marker="o", linewidth=1, label="train")
plt.legend()
plt.title('train and val loss vs. epoches')
plt.ylabel('loss')
plt.savefig("train and val loss vs epoches.jpg")
plt.close('all') # 关闭图 0

y5 = accuracy_list_species["train"]
y6 = accuracy_list_species["val"]
plt.plot(x, y5, color="r", linestyle="-", marker=".", linewidth=1, label="train")
plt.plot(x, y6, color="b", linestyle="-", marker=".", linewidth=1, label="val")
plt.legend()
plt.title('train and val Classes_acc vs. epoches')
plt.ylabel('Classes_accuracy')
plt.savefig("train and val Classes_acc vs epoches.jpg")
plt.close('all')

############################################ Visualization ###############################################
def visualize_model(model):
    model.eval()
    with torch.no_grad():
        for i, data in enumerate(data_loaders['val']):
            inputs = data['image']
            labels_species = data['species'].to(device)

            x_species = model(inputs.to(device))
            x_species=x_species.view( -1,3)
            _, preds_species = torch.max(x_species, 1)

            print(inputs.shape)
            plt.imshow(transforms.ToPILImage()(inputs.squeeze(0)))
            plt.title('predicted species: {}\n ground-truth species:{}'.format(species[preds_species],species[labels_species]))
            plt.show()

visualize_model(model)

